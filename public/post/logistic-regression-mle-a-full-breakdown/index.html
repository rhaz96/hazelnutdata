<!DOCTYPE html>
<html lang="en-us">
    <head>
        

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Logistic Regression MLE: A Thorough Breakdown</title>
        
        <style>

    html body {
        font-family: 'Georgia', sans-serif;
        background-color: #eee;
    }

    :root {
        --accent: purple;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Georgia">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/foundation.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
 

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
    
    <script>hljs.initHighlightingOnLoad();</script>






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.67.1" />
        

        

        
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        

        

    </head>

    <body>
        

        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">Logistic Regression MLE: A Thorough Breakdown</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/post/">Posts</a></li>
                            
                                <li><a href="/project/">Projects</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="https://github.com/rhaz96/statisticalmusings"><i class="fa fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/robertmhazell"><i class="fa fa-linkedin"></i></a></li>
                            
                        </ul>
                    
                </div>
            </div>
        </nav>


<main>

    <div>
        <h2>Logistic Regression MLE: A Thorough Breakdown</h2>
        <h5>October 11, 2020</h5>
        
<a href="/tags/technical"><kbd class="item-tag">technical</kbd></a>

<a href="/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>


    </div>

    <div align="start" class="content">


<div id="please-tell-me-more" class="section level3">
<h3>Please tell me more</h3>
<div class="tenor-gif-embed" data-postid="14192086" data-share-method="host" data-width="100%" data-aspect-ratio="1.7054794520547942">
<a href="https://tenor.com/view/tell-me-everything-in-detail-spill-the-tea-sips-tea-im-listening-gif-14192086">Tell Me Everything In Detail GIF</a> from <a href="https://tenor.com/search/tellmeeverything-gifs">Tellmeeverything GIFs</a>
</div>
<script type="text/javascript" async src="https://tenor.com/embed.js"></script>
<p><br></p>
<p>Sometimes the details behind mathematical proofs are relatively easy to infer, but when they’re not don’t we wish the details were spelt out? Sometimes books or online sources show steps 1, 2, and 5 without steps 3 and 4. And steps 1, 2, and 5 are sometimes better dealt with if the logic were fully fleshed out. Such is the case, in my opinion, when it comes to understanding maximum likelihood estimation (MLE) for logistic regression gradient descent. After working through the gory details by hand and different color inks, I felt the need to illustrate it to benefit anyone who may wish to see a full breakdown of how the gradient update function for logistic regression is derived.</p>
<p>To be clear it’s definitely not necessary to understand the mechanics behind the derivation in order to be a good ML practitioner, but since MLE with logistic regression tends to be the springboard by which neural networks are introduced, understanding it can lead to greater appreciation and comprehension of deep learning.</p>
<p>Get some caffeine - this will be long, but rewarding!</p>
</div>
<div id="part-1-motivating-logistic-regression" class="section level3">
<h3>Part 1: Motivating Logistic Regression</h3>
<p>We want to extend the linear regression model to handle classification. We all know the standard linear regression equation with <span class="math inline">\(p\)</span> predictors:</p>
<p><span style="color:purple"><span class="math display">\[\large y = \theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p\]</span></span></p>
<p>We want to modify this so that outputs fall between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> for classification purposes. This is classically done using the <em>logistic function</em>:</p>
<p><span style="color:SlateBlue"><span class="math display">\[\large \sigma (z) = \frac{e^{z}}{1+e^z}\]</span></span></p>
<p>where <span class="math inline">\(z\)</span> is some arbitrary scalar input.</p>
<p><img src="/post/2020-10-09-logistic-regression-mle-a-full-breakdown_files/logistic-function.png" /></p>
<p>The logistic function. Source: <a href="https://en.wikipedia.org/wiki/Logistic_function">Wikipedia</a>
<br>
<br></p>
<p>Our new equation is now:</p>
<p><span style="color:purple"><span class="math display">\[\large p(y) = \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}} = \sigma(y)\]</span></span></p>
<p>However, we’d like to work with a linear function, so instead of working with <span class="math inline">\(p(y)\)</span>, we use the odds of <span class="math inline">\(y\)</span> by dividing <span class="math inline">\(p(y)\)</span> by <span class="math inline">\(1-p(y)\)</span>. This is equivalent to saying divide <span class="math inline">\(\sigma(y)\)</span> by <span class="math inline">\(1-\sigma(y)\)</span></p>
<p><span class="math display">\[\large 1 - p(y) = 1 - \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}} =\frac{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}} - \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}\]</span></p>
<p><span class="math display">\[\large 1-p(y) = \frac{1}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}\]</span></p>
<p>Carry out the division of <span class="math inline">\(p(y)\)</span> and <span class="math inline">\(1-p(y)\)</span> by multiplying the former by the reciprocal of the latter:</p>
<p><span class="math display">\[\large \frac{p(y)}{1-p(y)} = \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}} * \frac{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1} = e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}\]</span></p>
<p>By taking the natural log of both sides, we get</p>
<p><span class="math display">\[\large ln\left (\frac{p(y)}{1-p(y)} \right ) = \theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p\]</span></p>
<p>This says that the log-odds that <span class="math inline">\(y=1\)</span> is given by <span class="math inline">\(\theta_{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p\)</span></p>
</div>
<div id="part-2-introducing-mle" class="section level3">
<h3>Part 2: Introducing MLE</h3>
<p>We just derived the functional form of logistic regression, but when it comes to determining optimal values of <span class="math inline">\(\theta_{0}, \theta_{1},..., \theta_{p}\)</span>, we usually use the formula for <span class="math inline">\(p(y)\)</span>. As a reminder</p>
<p><span class="math inline">\(\large p(y = 1) = \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}\)</span></p>
<p>To avoid the redundancy of the RHS, we’ll substitute it with <span class="math inline">\(\pi\)</span>, so that</p>
<p><span class="math inline">\(\large \pi = \frac{e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}{1 + e^{\theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p}}\)</span></p>
<p>This implies <span class="math inline">\(p(y = 0) = 1 - p(y = 1) = 1 - \pi\)</span></p>
<p>A way to reformulate this is by noting that</p>
<p><span class="math inline">\(\large p(Y = y) = \pi^y(1-\pi)^{1-y}\)</span>, with <span class="math inline">\(Y\)</span> being a random variable describing the values any particular instance can take on, which for binary classification is <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. So:</p>
<ul>
<li><p>if <span class="math inline">\(y=1\)</span>, <span class="math inline">\(p(Y = 1) = \pi^1(1-\pi)^{1-1} = \pi\)</span></p></li>
<li><p>if <span class="math inline">\(y=0\)</span>, <span class="math inline">\(p(Y = 0) = \pi^0(1-\pi)^{1-0} = 1-\pi\)</span></p></li>
</ul>
<p>as just stated above. We use this reformulation since it provides a <em>single equation</em> to calculate the probability of Y taking on <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.</p>
<p>If we assume the probability that each instance in our data belongs to either <span class="math inline">\(Y = 0\)</span> or <span class="math inline">\(Y=1\)</span> is independent, then the total probability of observing all our instances belonging to the classes we observe in our data (given our choice of thetas) is the <em>likelihood</em>, a simple application of the multiplication rule in probability for independent events:</p>
<p><span class="math inline">\(\large L = P(Y_1 = y_1, Y_2 = y_2, ..., Y_m = y_m) = \prod_{i=1}^{m}\pi^{y^{(i)}}(1-\pi)^{1-y^{(i)}}\)</span></p>
<p>There are <span class="math inline">\(m\)</span> instances in our dataset. We’re trying to determine the thetas that will maximize this likelihood function.</p>
</div>
<div id="part-3-prepping-for-gradient-ascent" class="section level3">
<h3>Part 3: Prepping for gradient ascent</h3>
<p>To make things easier, we’ll do two things:</p>
<ul>
<li><p>convert the likelihood to the log likelihood, so that we can deal with sums instead of products</p></li>
<li><p>perform gradient ascent for just a single instance to motivate how to update the logistic regression loss function for all instances.</p></li>
</ul>
<p>Examining gradient ascent for a single instance will make notation easier. For a single instance the likelihood <span class="math inline">\(L\)</span> is:</p>
<p><span class="math inline">\(\large L = \pi^y(1-\pi)^{1-y}\)</span></p>
<p>Taking the natural log on both sides to get the log-likelihood <span class="math inline">\(LL\)</span>:</p>
<p><span class="math inline">\(\large LL = ln\left [\pi^y \cdot (1-\pi)^{1-y} \right ]\)</span></p>
<p><span class="math inline">\(\large LL = ln(\pi^y) + ln\left [ (1-\pi)^{1-y} \right ]\)</span></p>
<p>Using properties of logs, we can bring the exponents to the front:</p>
<p><span class="math inline">\(\large LL = y\,ln(\pi) + (1-y)\,ln(1-\pi)\)</span></p>
</div>
<div id="part-4-gradient-ascent-using-the-chain-rule" class="section level3">
<h3>Part 4: Gradient ascent using the Chain Rule</h3>
<div class="figure">
<img src="/post/2020-10-09-logistic-regression-mle-a-full-breakdown_files/grad_asc_mountain.jpg" alt="Photo by Willian Justen de Vasconcellos on Unsplash" />
<p class="caption"><span>Photo by <a href="https://unsplash.com/@willianjusten?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Willian Justen de Vasconcellos</a> on <a href="https://unsplash.com/s/photos/gradient-descent?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span></p>
</div>
<p>Now we’re ready to perform the biggest part of the whole derivation. We will take the partial derivative of the log-likelihood <span class="math inline">\(LL\)</span> with respect to each theta for our single instance, all using the Chain Rule from calculus.</p>
<p>To avoid overloading the letter y, we’ll use <span class="math inline">\(g\)</span> to denote the linear combination of inputs, so that</p>
<p><span class="math inline">\(\large g = \theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p\)</span></p>
<p>and hence</p>
<p><span class="math inline">\(\large \pi = \sigma(g)\)</span></p>
<p>Now observe that <span class="math inline">\(LL\)</span> is a function of <span class="math inline">\(\pi\)</span>, and <span class="math inline">\(\pi\)</span> is a function of <span class="math inline">\(g\)</span>, and <span class="math inline">\(g\)</span> is a function of the <span class="math inline">\(\theta_j\)</span>’s, where <span class="math inline">\(j = 1, ..., p\)</span>.</p>
<p>Applying the Chain Rule, this implies</p>
<p><span class="math inline">\(\boxed {\large \frac{\partial LL}{\partial \theta_j} = \frac{\partial LL}{\partial \pi}\,\frac{\partial \pi}{\partial g}\,\frac{\partial g}{\partial \theta_j}}\)</span><br />
<br></p>
<div id="partial-of-ll-with-respect-to-pi" class="section level4">
<h4>4.1: Partial of <span class="math inline">\(LL\)</span> with respect to <span class="math inline">\(\pi\)</span></h4>
<p>Let’s start with <span class="math inline">\(\frac{\partial LL}{\partial \pi}\)</span>. Since</p>
<p><span class="math inline">\(\large LL = y\,ln(\pi) + (1-y)\,ln(1-\pi)\)</span></p>
<p>then by applying the Product Rule:</p>
<p><span class="math inline">\(\large \frac{\partial LL}{\partial \pi}\ = y\,\cdot \frac{\partial}{\partial \pi}\,ln(\pi)\, + ln(\pi)\,\cdot \frac{\partial}{\partial \pi}\,y\ + (1-y)\,\cdot \frac{\partial}{\partial \pi}\,ln(1-\pi) + ln(1-\pi)\,\cdot \frac{\partial}{\partial \pi}\,(1-y)\)</span></p>
<p>The second and fourth summands equal <span class="math inline">\(0\)</span> since neither <span class="math inline">\(y\)</span> nor <span class="math inline">\(1-y\)</span> include <span class="math inline">\(\pi\)</span>. So this simplifies to</p>
<p><span class="math inline">\(\large \frac{\partial LL}{\partial \pi}\ = y\,\cdot \frac{1}{\pi} - (1-y)\cdot \left ( \frac{1}{1-\pi} \right ) = \boxed{\frac{y}{\pi} - \left ( \frac{1-y}{1-\pi} \right )}\)</span></p>
<p><br></p>
</div>
<div id="partial-of-pi-with-respect-to-g" class="section level4">
<h4>4.2: Partial of <span class="math inline">\(\pi\)</span> with respect to <span class="math inline">\(g\)</span></h4>
<p>Now we move to the second portion of the partial of the log likelihood.</p>
<p><span class="math inline">\(\large \frac{\partial \pi}{\partial g} = \frac{\partial}{\partial g}\,\left ( \frac{e^g}{1+e^g} \right )\)</span></p>
<p>This is since <span class="math inline">\(\pi = \sigma(g)\)</span>, and plugging <span class="math inline">\(g\)</span> into the logistic function, <span class="math inline">\(\sigma(g) = \frac{e^g}{1+e^g}\)</span></p>
<p>Using the Quotient Rule</p>
<p><span class="math inline">\(\large \frac{\partial \pi}{\partial g} = \frac{(1+e^g)\,\cdot\frac{\partial}{\partial g}(e^g)\, - (e^g)\left ( \frac{\partial}{\partial g}\,(1+e^g) \right )}{(1+e^g)^2} =\frac{(1+e^g)(e^g)\, - (e^g)(e^g)}{(1+e^g)^2} = \frac{e^g + (e^g)^2 - (e^g)^2}{(1+e^g)^2} = \boxed{\frac{e^g}{(1+e^g)^2}}\)</span></p>
<p><br></p>
</div>
<div id="partial-of-g-with-respect-to-theta_j" class="section level4">
<h4>4.3: Partial of <span class="math inline">\(g\)</span> with respect to <span class="math inline">\(\theta_j\)</span></h4>
<p>Lastly we deal with perhaps the easiest part of the derivation.</p>
<p><span class="math inline">\(\large \frac{\partial\,g}{\partial\,\theta_j} = \frac{\partial }{\partial \theta_j}(\theta_0 + \theta_1x_1 + \cdots+\theta_px_p) = \boxed{x_j}\)</span></p>
<p>Any terms that don’t contain <span class="math inline">\(\theta_j\)</span> are considered constants, and taking the partial of those terms equals <span class="math inline">\(0\)</span>, leaving us with just <span class="math inline">\(x_j\)</span></p>
<p><br></p>
</div>
</div>
<div id="part-5-putting-it-all-together" class="section level3">
<h3>Part 5: Putting it all together</h3>
<p>Whew! Let’s put all the components from 4.1 to 4.3 together.</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = \left ( \frac{y}{\pi}-\frac{1-y}{1-\pi} \right )\left ( \frac{e^g}{(1+e^g)^2} \right )x_j\)</span></p>
<p>We can simplify the middle term by noting that <span class="math inline">\(\frac{e^g}{(1+e^g)^2} = \sigma(g)[1-\sigma(g)] = \pi(1-\pi)\)</span></p>
<p>So then:</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = \left ( \frac{y}{\pi}-\frac{1-y}{1-\pi} \right )\left ( \pi(1-\pi) \right )x_j\)</span></p>
<p>Bringing terms under a common denominator for the first term on the RHS:</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = \left ( \frac{y(1-\pi)}{(1-\pi)\pi} - \frac{(1-y)\pi}{(1-\pi)\pi} \right )\left ( \pi(1-\pi) \right )x_j\)</span></p>
<p>Simplifying:</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = \left ( \frac{y(1-\pi) - \pi(1-y)}{(1-\pi)\pi} \right )(\pi(1-\pi))x_j\)</span></p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = (y-y\pi-\pi+y\pi)x_j = (y-\pi)x_j = [y-\sigma(g)]x_j\)</span></p>
</div>
<div id="part-6-polishing-up" class="section level3">
<h3>Part 6: Polishing up</h3>
<p>We’ve fleshed out the tough stuff. But remember our derivation was just for a single instance. As there are <span class="math inline">\(m\)</span> instances, we need to update <span class="math inline">\(\theta_j\)</span> by taking all those instances into account.</p>
<p>So instead of just</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = [y-\sigma(g)]x_j\)</span>, we make this:</p>
<p><span class="math inline">\(\large \frac{\partial\,LL}{\partial\,\theta_j} = \sum_{i=1}^{m}[y^{(i)}-\sigma(g)]x_{j}^{(i)}\)</span></p>
<p>It’s additive because, as explained in Part 4, the log likelihood (<span class="math inline">\(LL\)</span>) allows us to use sums instead of products.</p>
<p>What was <span class="math inline">\(g\)</span> again? <span class="math inline">\(g = \theta _{0} + \theta _{1}x_1 + \cdots + \theta _{p}x_p\)</span>. In matrix notation this would be expressed as <span class="math inline">\(\boldsymbol{\theta}^T\mathbf{x}\)</span>. So then:</p>
<p><span class="math inline">\(\boxed{\large \frac{\partial\,LL}{\partial\,\theta_j} = \sum_{i=1}^{m}[y^{(i)}-\sigma(\boldsymbol{\theta}^T\mathbf{x}^{(i)})] x_{j}^{(i)}}\)</span></p>
<p>Now we know our update rule for any particular <span class="math inline">\(\theta_j\)</span> and learning rate <span class="math inline">\(\eta\)</span>:</p>
<p><span class="math inline">\(\large {\theta_{j}^{\,new} = \theta_{j}^{\,old} + \eta \sum_{i=1}^{m}[y^{(i)}-\sigma(\boldsymbol{\theta}^T\mathbf{x}^{(i)})] x_{j}^{(i)}}\)</span></p>
</div>
<div id="part-7-going-from-ascent-to-descent" class="section level3">
<h3>Part 7: Going from ascent to descent</h3>
<p>All along we worked with gradient <em>ascent</em>. It’s quite simple to write out the update rule for gradient <em>descent</em>. We simply switch the order of the terms in the bracket. In other words,</p>
<p><span class="math inline">\(\large \boxed{\theta_{j}^{\,new} = \theta_{j}^{\,old} + \eta \sum_{i=1}^{m}[\sigma(\boldsymbol{\theta}^T\mathbf{x}^{(i)}) - y^{(i)}] x_{j}^{(i)}}\)</span></p>
<p>To see why that makes sense, consider a simpler example. Suppose I was interested in <span class="math inline">\(\sum_{i=1}^{3}(3i^2 - 4i)\)</span> Evaluating this summation gives <span class="math inline">\(18\)</span>. To get <span class="math inline">\(-18\)</span> instead (analogous to going from gradient ascent to descent), you can verify that <span class="math inline">\(\sum_{i=1}^{3}(4i - 3i^2)\)</span> does indeed give <span class="math inline">\(-18\)</span>.</p>
</div>
<div id="wrapping-up" class="section level3">
<h3>Wrapping up</h3>
<p>I hope this gives you a more clear understanding of the derivation of the logistic regression update rule. I plan to write up detailed derivations for other machine learning algorithms in the future.</p>
</div>
</div>

    
    
    
        <h4 class="page-header">Related</h4>
         <div class="item">

    
    
    

    
    

    <h4><a href="/post/mean-variance-standardized-data/">Proving the Properties of the Mean and Variance of Standardized Data</a></h4>
    <h5></h5>
    
<a href="/tags/technical"><kbd class="item-tag">technical</kbd></a>



</div>
 
    

    
    

</main>

        <footer>
            <p class="copyright text-muted">© All rights reserved. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a>.</p>
        </footer>

        

        
    </body>

</html>

