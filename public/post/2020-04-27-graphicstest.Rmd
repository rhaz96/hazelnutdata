---
title: graphicstest
author: ''
date: '2020-04-27'
slug: graphicstest
categories: []
tags: []
---
<center>Authors: Robert Hazell, [Gavin Hudgeons](https://www.linkedin.com/in/gavin-hudgeons-2b61388/), [Bruce Lee](https://www.linkedin.com/in/bruce-lee-38227019/)</center>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F, comment=NA)
```

```{r echo=F}
library(reticulate)
use_python("/usr/local/bin/python3", required = T)
```

```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style('dark')
#plt.rcParams.update({'font.size': 18})
bankingDF = pd.read_csv("/Users/roberthazell/Desktop/SMU/ML1/bank-additional-full.csv")
```

# Part I - Exploratory Data Analysis

```{python}
# histogram of age
ax = sns.distplot(bankingDF["age"])
ax.grid(False)
plt.tick_params(labelsize=12)
plt.show()
```


There is some right skew in terms of the age range the bank targets, with the majority of customers targeted in their 30s-40s.  This makes sense as those in that age bracket would more likely have money to spend on long-term deposits given a stable income. Individuals past 60 years old are not considered, most likely since such are already retired; they should have made long-term deposits decades before!  

#### Job Categories

```{python}
fig, ax = plt.subplots(figsize=(20,10)) 
job_totals = bankingDF["job"].value_counts()
job_totals = pd.DataFrame({"Job Type": job_totals.index,
                         "Total": job_totals.values})

ax = sns.barplot(x = "Total", y="Job Type", data=job_totals,
                 palette="Blues_d")
ax.grid(False)
plt.tick_params(labelsize=20)
_=plt.xlabel("Total Prospects", fontsize = 22)
_=plt.ylabel("Job Type", fontsize = 22)
plt.show()

```

The bank tends to heavily profile blue-collar workers in that three of the top four job types are in the blue-collar sector.  The number one category -- ```admin``` -- is white-collar.

#### How frequent a prospect is called (current campaign) 

```{python}
_=plt.boxplot(bankingDF["campaign"], vert=False)
_=plt.xlabel("Number of times contacted", fontsize=20)
plt.grid(False)
fig = plt.gcf()
a = plt.gca()
_=a.axes.get_yaxis().set_ticks([])
fig.set_size_inches(18.5, 8)
plt.tick_params(labelsize=18)
plt.show()
```

On average the bank has been in contact less than 5 times for any given customer, but several were constantly targeted.  Perhaps these are highly promising but wavering customers. 

#### When are calls made?

```{python}
fig, ax = plt.subplots(figsize=(15,10)) 
# count number of calls by day
call_day = bankingDF["day_of_week"].value_counts()
# convert to dataframe
call_day = pd.DataFrame({"Day": call_day.index,
                         "Total": call_day.values})
# plot barplot of counts
ax = sns.barplot(call_day["Day"], call_day["Total"],
           palette="Purples_d")
ax.grid(False)
_=plt.xlabel('')
_=plt.ylabel("Calls Made", fontsize=20)
plt.tick_params(labelsize=18)
plt.show()
```

In terms of follow-up call days, bankers show some preference, most following up on Thursday and least on Fridays, but these differences don't seem significant.

#### Time elapsed since a prospect was previously called

```{python}
# plotting how long it took for a prospect to receive
# another campaign call

# remove people who were contacted for the first time
bank_pdays_filtered = bankingDF[bankingDF["pdays"] != 999]
# plot data this way to change x-axis label from default
ax = sns.violinplot(x="pdays",
                   data = bank_pdays_filtered,
                   color="turquoise")
#_=ax.set(xlabel = "Days since last contact")
ax.grid(False)
plt.tick_params(labelsize = 18)
_=plt.xlabel("Days since last contact", fontsize=19)
plt.show()
```

We see evidence of bimodality and right-skew from this violinplot, aspects not clearly seen in the inscribed boxplot.  

Bankers followed up with them roughly between 3 and 6 days after their latest call for most people in this data. The two peaks are perhaps indicative of early stage sale-pitching by the banks where communication is frequent.  For those in late-stage or completed negotiations, or people who constantly ignore campaign calls, the right skew probably reflects such cases.

#### Education level of prospects

```{python}
fig, ax = plt.subplots(figsize=(10,6)) 
education_totals = bankingDF["education"].value_counts()
education_totals = pd.DataFrame({"Education Type": education_totals.index,
                         "Total": education_totals.values})

my_range=range(1,len(education_totals.index)+1)
_=plt.hlines(y=my_range, xmin=0, xmax=education_totals['Total'], color='skyblue')
_=plt.plot(education_totals['Total'], my_range, "o")

_=plt.yticks(my_range, education_totals['Education Type'])
#_=plt.xlabel('People Called by Bank', fontsize=12)
#_=plt.ylabel('Education', fontsize=12)
_=plt.grid(False)
_=plt.tick_params(labelsize="small")
#_=ax.set_yticklabels(education_totals['Education Type'],rotation=20)
_=plt.show()
```

Code for lollipop chart adapted from [here](https://python-graph-gallery.com/182-vertical-lollipop-plot/).  As you'd expect the bank tends to target those who have, at the very least, completed high school.  Greatest preference is shown towards college educated individuals.  Again, this makes sense since they tend to earn more money relative to other education groups, making them likelier to deposit money.

### Explore Joint Attributes

#### Job and Education

```{python}
_=plt.subplots(figsize=(10,8)) 
_=sns.heatmap(pd.crosstab(bankingDF["education"],bankingDF["job"]),
            annot=True, fmt="g")
plt.tick_params(rotation=45, labelsize=7)
_=plt.ylabel("Education")
_=plt.xlabel("Job")
plt.show()
```

We can visualize a cross tabulation between education level and job status.  There isn't much to be said for ```illiterate``` folks, but for those with ```unknown``` education tend to work blue-collar, admin, and technician type jobs.  The most blue collar employees are those with ```basic.4y```, ```basic.6y```, and ```basic.9y``` educations.  It's not clear what these categories represent.  College educated individuals work predominantly as admins, in management, or as technicians.  High school grads also work in large proportion within admin, but also in the services industry.  

#### Consumer Confidence and Consumer Price Indexes

```{python}
ax = sns.lmplot( x="cons.price.idx", y="cons.conf.idx", 
               data=bankingDF, fit_reg=True, line_kws={'color': 'red'})
plt.grid(False)
_=plt.xlabel("Price Index")
_=plt.ylabel("Confidence Index")
plt.rcParams.update({'font.size': 12})
plt.show()
```

Almost no correlation is present between consumer confidence and the price index.  That being said, the price index is relatively consistent in this data, ranging from ~ 92 to ~ 95, so it's unsurprising to see a flat relationship between these variables (the correlation is ~ 0.06).  Consumer confidence was negative in Portugal throughout 2014 (when this data was taken) and has been that way for nearly the past decade, as can be seen [here](https://tradingeconomics.com/portugal/consumer-confidence).  As an aside, that the correlation between price index and consumer confidence is slightly *positive* is mildly interesting.

#### Month and Day of Week of Contact

```{python}
pd.crosstab(bankingDF["day_of_week"],bankingDF["month"])
```

```{python}
fig, ax = plt.subplots(figsize=(15,10)) 
day_and_month = pd.crosstab(bankingDF["day_of_week"],bankingDF["month"])
day_and_month = day_and_month.reindex(['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep','oct', 'nov', 'dec'], axis=1).reindex(["mon","tue","wed","thu","fri"])
_=sns.heatmap(day_and_month, annot=True, fmt="d", cmap="YlGnBu", ax=ax,annot_kws={"size":16})
_=plt.xlabel("")
_=plt.ylabel("")
_=plt.tick_params(labelsize=15)
plt.show()
```

The most popular months for calling are the late spring and summer months: May through August.  The least popular months were in the fall and winter (September, October, and December), although November marks an uptick in campaign calling.  There is no data for January or February, implying the latest campaign began in March.

#### Timing of return call depending on previous campaign outcome


```{python}
# filter out the first-time calls
outcome = bankingDF.loc[bankingDF["poutcome"].isin(["failure", "success"])]
# find mean time elpased from previous campaign call
outcome_tab = outcome[outcome["pdays"] != 999].groupby("poutcome").agg({"pdays":"mean"})
outcome_tab.index.names = ["Prev. Call Outcome"]
outcome_tab.rename(columns = {"pdays": "Avg. Days Until Next Call"})
```

On average, if a previous campaign call failed, the bank would wait about twice as long to recall the prospect compared to recall time for previous campaign calls that succeeded.

### Explore Attributes and Prediction Class

#As is often the case, this class is imbalanced.  People tend to reject the bank's #offers, so oversampling those who didn't reject (those who do subscribe to a term #deposit) is needed in the future.


#### Education and Subscribers

```{python}
# all those who subscribed, grouped by education
accepted = bankingDF[bankingDF["y"] == "yes"].groupby("education").agg({"y":"count"}).reset_index()
accepted = accepted.sort_values('y')

# lollipop plot
my_range=range(1,len(accepted.index)+1)
sns.set_style('dark')
fig, ax = plt.subplots(figsize=(8,6)) 
_=plt.hlines(y=my_range, xmin=0, xmax=accepted['y'], color='maroon')
_=plt.plot(accepted['y'], my_range, "o", color = 'maroon')
_=plt.yticks(my_range, accepted['education'], rotation=45)
_=plt.xlabel('Contacts who accepted bank offer')
_=plt.tick_params(labelsize=10)
_=plt.ylabel('Education Level')
```

The majority who sign up with the bank are college educated, but the pattern above is almost identical for those who reject the bank.  This suggests the need to examine prevalence rates across education levels, as will be seen later.


#### Call Duration and Outcome (Non First time calls)

The vast majority of bank calls are to first time contacts, so we'll like to see the call distributions for non-first timers.

```{python}
first_timers = len(bankingDF[bankingDF["pdays"] == 999]) / bankingDF.shape[0]
print("Proportion of first time calls: ", round(first_timers, 3))
```

```{python}
success = bankingDF[(bankingDF['y'] == "yes") & (bankingDF['pdays']!=999)]
fail = bankingDF[(bankingDF['y'] == "no") & (bankingDF['pdays']!=999)]

fig, ax = plt.subplots(figsize = (12,8))
for a in [success, fail]:
    _=sns.distplot(a["duration"], bins=range(1, 3600, 20), ax=ax, kde=False)
_=ax.set_xlim([0, 4000])
_=fig.legend(labels = ["Subscribed","Rejected"], fontsize=12)
_=plt.xlabel("Duration of Last Phone Call (Seconds)", fontsize=14)
_=plt.grid(False)
_=plt.tick_params(labelsize=13)
#plt.rcParams.update({'font.size': 18})
_=plt.show()
```

[As is pointed out](https://archive.ics.uci.edu/ml/datasets/bank+marketing) call duration isn't known before the bank makes a call, and the outcome of the call is known immediately after a call.  So ```duration``` can't be used as a predictor when building a model.  Nevertheless, for those who've been contacted before, bank-rejecters spend on average less time engaging with the bank agent.  The distribution of talk time is right-skewed regardless of call outcome.  When analyzing the response and ```duration``` it needs to be done in a retrospective manner.

#### Day of Week and Subscriptions


```{python}
fig, ax = plt.subplots(figsize=(5,5)) 
_=sns.heatmap(pd.crosstab(bankingDF["day_of_week"],bankingDF[bankingDF['y'] == "yes"]["y"]).reindex(["mon","tue","wed","thu","fri"]),
            annot=True,ax=ax, fmt="g")

_=ax.set_xlabel("")
_=ax.set_ylabel("")
plt.rcParams.update({'font.size': 18})
plt.show()
```

The most successes come on Thursdays, followed by a near tie between Tuesday and Wednesday.  It seems like the beginning and end of the week are the least favorable days to call.

#### Job Profession of those who Subscribe

```{python}
fig, ax = plt.subplots(figsize=(10,6)) 
# all those who subscribed, grouped by education
accepted = bankingDF[bankingDF["y"] == "yes"].groupby("job").agg({"y":"count"}).reset_index()
accepted = accepted.sort_values('y')

# lollipop plot
my_range=range(1,len(accepted.index)+1)
sns.set_style('dark')
_=plt.hlines(y=my_range, xmin=0, xmax=accepted['y'])
_=plt.plot(accepted['y'], my_range, "o", color="black")
_=plt.yticks(my_range, accepted['job'])
_=plt.tick_params(axis="y", labelsize=8, rotation=30)
_=plt.tick_params(axis="x", labelsize=11)
_=plt.xlabel('Contacts who accepted bank offer', fontsize=12)
_=plt.ylabel('Job Type', fontsize=12)
```

Interestingly, ```retired``` folks were one of the least targeted groups (look back at the ```age``` histogram) that ended up subscribing quite often.

#### Prevalance Rates by Job Category

The plot immediately above gives the raw values of subscribers by job type.  We also know the overall prevalence rate is ~ 11%.  Perhaps there's quite a bit of imbalance between education or job positions so we'll see if prevalence rates differ by category.

```{python}
_=plt.subplots(figsize=(8,6)) 
# those who accept by job category
job_yes = (bankingDF[bankingDF["y"] == "yes"]
    .groupby('job')
    .agg({'y':'count'})
    .rename(columns = {'y':'Subscribed'})
    .reset_index())

# total number of people in each job category
# regardless of subscription status
all_job = (bankingDF
    .groupby('job')
    .agg({'y':'count'})
    .rename(columns = {'y':'Job Total'})
    .reset_index())

# calculate prevalence rates
job_yes['Job Total'] = all_job["Job Total"]
job_yes["Prevalence Rate"] = job_yes["Subscribed"]/job_yes["Job Total"]
job_yes = job_yes.sort_values("Prevalence Rate", ascending=False)


_= sns.barplot(job_yes["job"], job_yes["Prevalence Rate"],
           palette=sns.cubehelix_palette(12, reverse=True),
          )

_=plt.xlabel("")
_=plt.tick_params(axis="x", labelsize=8, rotation=30)
_=plt.tick_params(axis="y", labelsize = 11)
_=plt.ylabel("Prevalence Rate", fontsize = 12)
plt.show()

```

```{python}
job_yes.set_index("job")
```

Perhaps surprisingly, ```student```s have the highest prevalence (~31.4%) albeit being one of the least targeted demographics.  By contrast ```blue-collar``` prospects were second most called (see "Education Levels" section) yet had the lowest conversion rate at ~ 6.9%.  This plot confirms raw values give an incomplete picture of conversion. We can summarize the first fact with this simple text graphic below.


```{python}
fig, ax = plt.subplots(figsize=(6,6)) 
_=plt.text(0.29, 0.6, "31%", size=40,
         va="baseline", ha="right", multialignment="left",
         color = "green"
        )

_=plt.text(0.8, 0.6, "of students converted...", size=16,
         va="baseline", ha="right", multialignment="left"
         )

_=plt.text(0.15, 0.4, "...yet made up only", size=16,
         va="baseline", ha="left", multialignment="left"
         )

_=plt.text(0.57, 0.4, "2%", size=20,
         va="baseline", ha="left", multialignment="left",
         color="red"
         )

_=plt.text(0.67, 0.4, "of contacts", size=16,
         va="baseline", ha="left", multialignment="left"
         )

plt.gca().axes.get_yaxis().set_visible(False)
plt.gca().axes.get_xaxis().set_visible(False)
plt.show()
```

The bank should consider reaching out to students more.

#### Prevalence Rates by Education Level

We now do the same analysis for education.


```{python}
educ_yes = (bankingDF[bankingDF["y"] == "yes"]
    .groupby('education')
    .agg({'y':'count'})
    .rename(columns = {'y':'Subscribed'})
    .reset_index())

# total number of people in each job category
# regardless of subscription status
all_educ = (bankingDF
    .groupby('education')
    .agg({'y':'count'})
    .rename(columns = {'y':'Education Total'})
    .reset_index())

# calculate prevalence rates
educ_yes['Education Total'] = all_educ["Education Total"]
educ_yes["Prevalence Rate"] = educ_yes["Subscribed"]/educ_yes["Education Total"]
educ_yes = educ_yes.sort_values("Prevalence Rate", ascending=False)


_=sns.barplot(educ_yes["education"], educ_yes["Prevalence Rate"],
           color="skyblue")

_=plt.tick_params(axis="x", labelsize=8, rotation=30)
_=plt.tick_params(axis="y", labelsize = 11)
_=plt.ylabel("Prevalence Rate", fontsize = 12)
plt.show()
```






