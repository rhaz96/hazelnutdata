<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Statistical Musings</title>
    <link>/post/</link>
    <description>Recent content in Posts on Statistical Musings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Logistic Regression MLE: A Thorough Breakdown</title>
      <link>/post/logistic-regression-mle-a-full-breakdown/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/logistic-regression-mle-a-full-breakdown/</guid>
      <description>Prologue The Logistic function. Source: Wikipedia

It’s a bit disconcerting when textbooks or online sources provide derivations without fully spelling out the details. They’ll sometimes show steps 1, 2, and 5 without steps 3 and 4. And steps 1, 2, and 5 are sometimes better dealt with if the logic were fully fleshed out. Such is the case, in my opinion, when it comes to understanding maximum likelihood estimation (MLE) for logistic regression gradient descent.</description>
    </item>
    
    <item>
      <title>Visualizing WHO health data better than the WHO</title>
      <link>/post/visualizing-world-bank-health-data-better-than-the-world-bank/</link>
      <pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/visualizing-world-bank-health-data-better-than-the-world-bank/</guid>
      <description>Can we do better than this? The World Health Organization (WHO), in coordination with the World Bank, maintains data on a variety of topics, including global health care expenditure. They’ve recorded data between 2000 and 2017 on how the world spends its money on healthcare. Here’s their actual data viz.
Figure 1: WHO visualization on global health spending between 2000 and 2017. Source: WHO 
This hardly looks like an effective visualization by Cole Nussbaumer Knaflic’s standards in her book Storytelling with Data, so let’s see how we can improve this to better align with her advice on effective visualizations.</description>
    </item>
    
    <item>
      <title>Grokking the Permutation Test</title>
      <link>/post/grokking-the-permutation-test/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/grokking-the-permutation-test/</guid>
      <description>p.caption { font-size: 0.8em; }   Sheep wool experiment, taken from Jared Wilber  
Jared Wilber has an amazing interactive visualization illustrating the permutation test. I highly recommend reading it to get a better visual intuition of how the test statistic of the permutation test is derived.
However I feel not enough emphasis was given on the logic of why the permutation test works to begin with.</description>
    </item>
    
    <item>
      <title>A Random Walk with Dice</title>
      <link>/post/a-random-walk-with-dice/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/a-random-walk-with-dice/</guid>
      <description>p.caption { font-size: 0.8em; }  Photo by Jonathan Petersson on Unsplash
 I recently came across an interesting probability question from Nate Rosidi, maintainer of the data science prep site Strata Scratch. This question was asked by FiveThirtyEight and goes like this:
 You start with a fair 6-sided die and roll it six times, recording the results of each roll. You then write these numbers on the six faces of another, unlabeled fair die.</description>
    </item>
    
    <item>
      <title>When are lines linear functions in linear algebra?</title>
      <link>/post/lines-not-linear-functions/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/lines-not-linear-functions/</guid>
      <description>Wait, what? We were all probably taught in algebra or geometry class that all lines are linear functions. So presumably \(y = 2x+3\) is supposed to be a linear function in linear algebra…except that it’s not. In fact equations of the form \(y = mx+b\) are not considered linear functions, except under special conditions which will be explained a bit later. All this raises the question: what are linear functions?</description>
    </item>
    
    <item>
      <title>Comparing Interaction Terms in Log-Log Regression Models</title>
      <link>/post/log-log-interaction/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/log-log-interaction/</guid>
      <description>p.caption { font-size: 0.8em; }   The venerable House Price Competition on Kaggle  
In the graduate statistics class I’ve TA’ed, we explore a range of regression concepts, both theory and practice. This includes linear and polynomial regression, as well as transformations to align data to certain regression modeling assumptions. At the end of the course, students complete form groups to work on a project…the Kaggle housing prices competition on Ames, Iowa - perhaps the most well known and ongoing competition.</description>
    </item>
    
    <item>
      <title>Working around LaTeX and Plotly issue in Hugo Minimal</title>
      <link>/post/latex-plotly-issue-hugo-minimal/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/latex-plotly-issue-hugo-minimal/</guid>
      <description>I’ve noticed some wierd quirks about Hugo Minimal, which is the theme used for this website. There’s no indication it supports by default rendering of LaTeX with MathJax. However, I have no problem rendering LaTeX - see this post of mine for example.
What is problematic for me is including a plotly chart in a document that contains LaTeX. Plotly is nice if you want to include interactive plots in your documents.</description>
    </item>
    
    <item>
      <title>Proving the Properties of the Mean and Variance of Standardized Data</title>
      <link>/post/mean-variance-standardized-data/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/mean-variance-standardized-data/</guid>
      <description>Some Background There’s a lot of concepts we take for granted in applied statistics, like the CLT or properties of the mean and variance for standardized data. And that’s totally fine! Our job as applied analysts is to properly understand and implement statistical methods to derive value for whomever our stakeholders are.
That being said, it’s a good idea whenever possible to understand why things are the way they are.</description>
    </item>
    
    <item>
      <title>An Intuitive Explanation of p-values</title>
      <link>/post/an-intuitive-explanation-of-p-values/</link>
      <pubDate>Sat, 28 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/an-intuitive-explanation-of-p-values/</guid>
      <description>Striving for p-value enlightenment Trying to describe p-values is notoriously difficult, even for seasoned statistics professionals. This article from FiveThirtyEight has been at the back of my head for the longest time. The author Christie Aschwanden is basically fishing around for a basic, intuitive definition of a p-value. Her conclusion?
 “What I learned by asking all these very smart people to explain p-values is that I was on a fool’s errand.</description>
    </item>
    
    <item>
      <title>Clearing Some Confusion about the Central Limit Theorem</title>
      <link>/post/clt_revisited/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/clt_revisited/</guid>
      <description>p.caption { font-size: 0.8em; }     A Normal Distribution  What’s the Problem? For quite awhile I was wondering about a potential disconnect in the way the Central Limit Theorem (a.k.a CLT) is taught and how it’s applied. Usually in statistics textbooks and online tutorials the reasoning goes like this:
 Step 1: Collect a set of observations (say, 20) and calculate the mean of that one sample of data Step 2: Collect another set of 20 observations and calculate the mean of that second sample of data Step 3: Repeat this process many, many times (say 10,000 times) Step 4: You now have 10,000 sample means.</description>
    </item>
    
  </channel>
</rss>